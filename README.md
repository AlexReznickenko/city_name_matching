# Решение для сопоставления гео названий с унифицированными именами geonames для внутреннего использования Карьерным центром Яндекс Практикум

<b>Цель: </b>

Сопоставление произвольных гео названий с унифицированными именами geonames для внутреннего использования Карьерным центром.

<b>Используемые для решения задачи данные:</b>

В рамках данной задачи, были использованы данные, взятые с сайта <a>http://download.geonames.org/export/dump/</a>, а именно файлы alternateNamesV2, cities15000, countryInfo. Заметим, что эти данные использовались именно для построения решения задачи. Заказчик может использовать в практических целях другие данные. Это необходимо учесть в процессе решения задачи. Кроме того, заказчик предоставил файл 
geo_test.csv для тестирования модели. 

<b>Задачи:</b>


- Создать решение для подбора наиболее подходящих названий с geonames. Например Ереван -> Yerevan. Помимо городов, там могут быть и страны.


- На примере РФ и стран наиболее популярных для релокации - Беларусь, Армения, Казахстан, Кыргызстан, Турция, Сербия. Города с населением от 15000 человек (с возможностью масштабирования на сервере заказчика)


- Возвращаемые поля geonameid, name, region, country, cosine similarity
- формат данных на выходе: список словарей, например [{dict_1}, {dict_2}, …. {dict_n}] где словарь - одна запись с указанными полями
- 
### Краткое описание проекта

Суть задачи сводится к тому, чтобы сопоставить введённое пользователем слово со словами из таблицы с унифицировннаыми названиями (в нашем случае, cities15000), и выбрать топ-k наиболее близких к нему, где k определяется заказчиком (например, топ-5 или любое другое количество). 

Для этого было решено предварительно векторизовать слова из спика унифицированных названий, а также введённое пользователем слово и затем искать косинусное сходство между векторами. Далее мы узнаём ближайшие топ-k geoname_id и по ним ищем унифицированные названия городов и другую необходимую информацию. Можно было бы векторизовать все слова из таблицы alternateNamesV2, но даже с учётом ограниченной выборки, поиск по векторам занимал бы большое количество времени (порядка 40-60 секунд для одного предсказания), что слишком много для практического применения.

Для создания веторов было решено использовать предобученные нейронные сети Sentence Transformers. Эти нейронные сети уже обучены на большом количестве текстов, и даже без дополнительного обучения, некоторые из них способны решить задачи. Они находятся на сайте <a>https://huggingface.co/sentence-transformers</a>. 

В рамках решения задачи была выбрана нейросеть <a>https://huggingface.co/sentence-transformers/distiluse-base-multilingual-cased-v2</a>. Она показывает неплохие результаты, и кроме того, достаточно "лёгкая" для того, чтобы её можно было дообучить с имеющимися мощностями. Модель <a>https://huggingface.co/sentence-transformers/LaBSE</a> показывала лучшие результаты "из коробки", то есть без дообучения, однако для того, чтобы её дообучать, необходимы недоступные вычислительные мощносити. В результате, выбранная модель с учётом дообучения победила.

Для улучшения показателй было решено дообучить её на выборке из таблицы alternateNamesV2, сопоставив альтернативные и истинные названия. Кроме того, для увеличения эффективности обучения было решено предобработать данные, приведя их к единому виду (нечто вроде лемматизации) и расширить обучающую выборку, добавив в неё также альтернативные названия со случайными опечатками, сгенерированными скриптом. 

### Стадии решения задачи:

- Загрузка необходимых данных из датабазы : соединение с postgreSQL базой данных, создания запросов, которые выгрузят необходимую выборку по странам. Обзор данных.

- Подготовка данных для обучения : лемматизация городов из alternateNamesV2; сопоставление их с унифицированными названиеми по geonameid;объединение с названиями стран. Данные по странам были также расширены - туда вручную были внесены альтернативные названия (в основном, перевод названий стран на русский язык) и им искуственно присвоен уникальный geonameid; расширение обучающей выборки методом добавления случайных опечаток.

- Обучение модели и сохранение обученной модели.

- Векторизация городов и стран с помощью обученной модели.

- Тестирование получившейся модели.

- Итоговая функция, возвращающая требуемый список словарей.

### Дополнительные возможности 

Настройка подключение к базе данных. Большое количество настроек, которые позволят заказчику настроить названия таблиц и столбцов, выгружаемых из базы данных, а также настройки обучения модели и сохранения промежуточных данных.

## Итоговый результат

- Мы настроили подключение к базе данных. Таким образом, программа работает непосредственно с базой данных заказчика.
- Были созданы настройки, благодаря которым заказчик сможет использовать любые данные схожей структуры. Он сможет использовать свои названия для схем данных и колонок, таким образом ему не придётся вмешиваться в код программы, чтобы подстроить её под свои данные или же менять названия своих данных (но важно чтобы структура данных сохранялась)
- Программа записывает в базу данных заказчика готовые эмбеддинги, таким образом, ему не придётся каждый раз заново рассчитывать их.
- Был создан скрипт, который создаёт и считывает дополнительную схему данных, в которой указывается, требуется ли повторное обучение модели и создание эмбеддингов. Более того, программа может считать эти настройки из базы данных, таким образом не обязательно каждый раз менять значения соответствующих констант.
- Была самостоятельно создана таблица с дополнительными альтернативными названиями для стран.
- Были созданы настройки обучения модели. Таким образом, заказчик может поменять параметры обучения просто поменяв значения некоторых констант.
- Был создан (также настраиваемый) скрипт для предподготовки данных (который включает в себя и аугментацию)
- Была обучена модель, основанная на  distiluse-base-multilingual-cased-v2. Обучение длилось 4 эпохи. Модель показала результаты accuracy = 0.925, значение accuracy*5 = 0.939. Она умеет справляться с опечатками, как было сказано в ТЗ.
- Была создана финальная функция predict(), которая принимает слово и возвращает список словарей, соответсвующий техническому задания. При том, в функции есть настройка, позволяющая выдавать вместо списка словарей датафрейм, что может быть удобней для тестирования непосредственно в теле программы. Также, согласно ТЗ, в функцию добавлен параметр, определяющий длину возвращаемого списка.
- Модель также умеет определять страны, не только города.

## Стек
pandas, sentence_transformers, numpy, sqlalchemy

## Состав проекта:
| **Название файла**  | **Содержание**                            |
|:--------------------|:------------------------------------------|
| [cities.ipynb](https://github.com/AlexReznickenko/city_name_matching/blob/main/cities.ipynb)         | основной ноутбук с проектом |
| [setup.py](https://github.com/AlexReznickenko/city_name_matching/blob/main/setup.py)        | файл с настройками для подключения к базе данных |         |
| [data](https://github.com/AlexReznickenko/city_name_matching/tree/main/data)          | папка с данными |
| [more_alternate_names_countries.csv](https://github.com/AlexReznickenko/city_name_matching/blob/main/data/more_alternate_names_countries.csv)          | сформированный вручную датасет с альтернативными названиями стран 
| [geo_test] отсутствует в репозитории         | папка с данными |
| [requirements.txt](https://github.com/AlexReznickenko/city_name_matching/blob/main/requirements.txt)    | requirements.txt    

## Ссылка на обученную модель
https://huggingface.co/AlexRez/distiluse-base-multilingual-cased-v2-4epochs-CITIESFINDER/tree/main
